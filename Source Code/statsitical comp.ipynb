{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881867ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from autorank import autorank, plot_stats, create_report, latex_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f6d319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>LGB</th>\n",
       "      <th>DNN</th>\n",
       "      <th>TabNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.758144</td>\n",
       "      <td>0.773201</td>\n",
       "      <td>0.700473</td>\n",
       "      <td>0.770360</td>\n",
       "      <td>0.825852</td>\n",
       "      <td>0.850568</td>\n",
       "      <td>0.847254</td>\n",
       "      <td>0.777367</td>\n",
       "      <td>0.868466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.740685</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.632229</td>\n",
       "      <td>0.696733</td>\n",
       "      <td>0.779236</td>\n",
       "      <td>0.783989</td>\n",
       "      <td>0.786432</td>\n",
       "      <td>0.602162</td>\n",
       "      <td>0.701880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.720261</td>\n",
       "      <td>0.709215</td>\n",
       "      <td>0.615489</td>\n",
       "      <td>0.673672</td>\n",
       "      <td>0.724484</td>\n",
       "      <td>0.738015</td>\n",
       "      <td>0.741355</td>\n",
       "      <td>0.652592</td>\n",
       "      <td>0.683856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.737368</td>\n",
       "      <td>0.702105</td>\n",
       "      <td>0.705789</td>\n",
       "      <td>0.794211</td>\n",
       "      <td>0.793421</td>\n",
       "      <td>0.788158</td>\n",
       "      <td>0.783158</td>\n",
       "      <td>0.777105</td>\n",
       "      <td>0.666579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.673045</td>\n",
       "      <td>0.701683</td>\n",
       "      <td>0.927572</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>0.969319</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.970826</td>\n",
       "      <td>0.922027</td>\n",
       "      <td>0.975857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.810462</td>\n",
       "      <td>0.793846</td>\n",
       "      <td>0.699385</td>\n",
       "      <td>0.802154</td>\n",
       "      <td>0.865077</td>\n",
       "      <td>0.857231</td>\n",
       "      <td>0.857385</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.885385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.784588</td>\n",
       "      <td>0.808672</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.879537</td>\n",
       "      <td>0.907827</td>\n",
       "      <td>0.909296</td>\n",
       "      <td>0.914930</td>\n",
       "      <td>0.890865</td>\n",
       "      <td>0.873863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.818991</td>\n",
       "      <td>0.820396</td>\n",
       "      <td>0.895279</td>\n",
       "      <td>0.961081</td>\n",
       "      <td>0.966468</td>\n",
       "      <td>0.962450</td>\n",
       "      <td>0.954432</td>\n",
       "      <td>0.954378</td>\n",
       "      <td>0.915387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.785514</td>\n",
       "      <td>0.557053</td>\n",
       "      <td>0.753946</td>\n",
       "      <td>0.830062</td>\n",
       "      <td>0.857935</td>\n",
       "      <td>0.859778</td>\n",
       "      <td>0.861656</td>\n",
       "      <td>0.798529</td>\n",
       "      <td>0.814330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.775418</td>\n",
       "      <td>0.640159</td>\n",
       "      <td>0.770052</td>\n",
       "      <td>0.863257</td>\n",
       "      <td>0.898207</td>\n",
       "      <td>0.898989</td>\n",
       "      <td>0.902871</td>\n",
       "      <td>0.867163</td>\n",
       "      <td>0.858606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.590307</td>\n",
       "      <td>0.740494</td>\n",
       "      <td>0.711271</td>\n",
       "      <td>0.700796</td>\n",
       "      <td>0.735241</td>\n",
       "      <td>0.735237</td>\n",
       "      <td>0.737580</td>\n",
       "      <td>0.673854</td>\n",
       "      <td>0.738760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SVM        NB       KNN        DT        RF       XGB       LGB  \\\n",
       "0   0.758144  0.773201  0.700473  0.770360  0.825852  0.850568  0.847254   \n",
       "1   0.740685  0.781805  0.632229  0.696733  0.779236  0.783989  0.786432   \n",
       "2   0.720261  0.709215  0.615489  0.673672  0.724484  0.738015  0.741355   \n",
       "3   0.737368  0.702105  0.705789  0.794211  0.793421  0.788158  0.783158   \n",
       "4   0.673045  0.701683  0.927572  0.960274  0.969319  0.972336  0.970826   \n",
       "5   0.810462  0.793846  0.699385  0.802154  0.865077  0.857231  0.857385   \n",
       "6   0.784588  0.808672  0.788732  0.879537  0.907827  0.909296  0.914930   \n",
       "7   0.818991  0.820396  0.895279  0.961081  0.966468  0.962450  0.954432   \n",
       "8   0.785514  0.557053  0.753946  0.830062  0.857935  0.859778  0.861656   \n",
       "9   0.775418  0.640159  0.770052  0.863257  0.898207  0.898989  0.902871   \n",
       "10  0.590307  0.740494  0.711271  0.700796  0.735241  0.735237  0.737580   \n",
       "\n",
       "         DNN    TabNet  \n",
       "0   0.777367  0.868466  \n",
       "1   0.602162  0.701880  \n",
       "2   0.652592  0.683856  \n",
       "3   0.777105  0.666579  \n",
       "4   0.922027  0.975857  \n",
       "5   0.822000  0.885385  \n",
       "6   0.890865  0.873863  \n",
       "7   0.954378  0.915387  \n",
       "8   0.798529  0.814330  \n",
       "9   0.867163  0.858606  \n",
       "10  0.673854  0.738760  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(r\"C:\\Users\\shubh\\Desktop\\XGB DNN\\1407\\res\\AUROC_baseline.csv\")\n",
    "df = pd.read_csv(r\"C:\\Users\\shubh\\Desktop\\XGB DNN\\1407\\res\\Accuracy_fs.csv\")\n",
    "#df = df.drop('MLP',axis=1)\n",
    "df = df.iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fd6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to reject null hypothesis that data is normal for column SVM (p=0.138323>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column NB (p=0.267302>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column KNN (p=0.330895>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column DT (p=0.520276>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column RF (p=0.655137>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column XGB (p=0.521510>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column LGB (p=0.547126>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column DNN (p=0.710614>=0.001111)\n",
      "Fail to reject null hypothesis that data is normal for column TabNet (p=0.365368>=0.001111)\n",
      "RankResult(rankdf=\n",
      "            mean       std  ci_lower  ci_upper effect_size   magnitude  \\\n",
      "LGB     0.850716  0.081031  0.702882   0.99855         0.0  negligible   \n",
      "XGB     0.850550  0.082198  0.700586  1.000514    0.002039  negligible   \n",
      "RF      0.847552  0.084504   0.69338  1.001723    0.038226  negligible   \n",
      "TabNet  0.816633  0.103411  0.627968  1.005299    0.366886       small   \n",
      "DT      0.812012  0.099328  0.630797  0.993228    0.426996       small   \n",
      "DNN     0.794368  0.113774  0.586795   1.00194     0.57051      medium   \n",
      "KNN     0.745474  0.097346  0.567874  0.923075    1.175088       large   \n",
      "SVM     0.744980  0.066229   0.62415   0.86581    1.428849       large   \n",
      "NB      0.729875  0.079430  0.584961  0.874789    1.506099       large   \n",
      "\n",
      "        p_equal  p_smaller      decision  \n",
      "LGB         NaN        NaN            NA  \n",
      "XGB     1.00000    0.00000         equal  \n",
      "RF      0.95234    0.04732  inconclusive  \n",
      "TabNet  0.00110    0.99078       smaller  \n",
      "DT      0.00078    0.99918       smaller  \n",
      "DNN     0.00026    0.99974       smaller  \n",
      "KNN     0.00000    1.00000       smaller  \n",
      "SVM     0.00000    1.00000       smaller  \n",
      "NB      0.00022    0.99978       smaller  \n",
      "pvalue=None\n",
      "cd=None\n",
      "omnibus=bayes\n",
      "posthoc=bayes\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.7106139659881592, 0.36536794900894165, 0.5471261143684387, 0.6551371812820435, 0.33089450001716614, 0.2673018276691437, 0.1383233219385147, 0.5215098857879639, 0.5202761888504028]\n",
      "homoscedastic=None\n",
      "pval_homogeneity=None\n",
      "homogeneity_test=None\n",
      "alpha=0.01\n",
      "alpha_normality=0.0011111111111111111\n",
      "num_samples=11\n",
      "posterior_matrix=\n",
      "        LGB              XGB                           RF  \\\n",
      "LGB     NaN  (0.0, 1.0, 0.0)  (0.04732, 0.95234, 0.00034)   \n",
      "XGB     NaN              NaN      (0.03294, 0.96706, 0.0)   \n",
      "RF      NaN              NaN                          NaN   \n",
      "TabNet  NaN              NaN                          NaN   \n",
      "DT      NaN              NaN                          NaN   \n",
      "DNN     NaN              NaN                          NaN   \n",
      "KNN     NaN              NaN                          NaN   \n",
      "SVM     NaN              NaN                          NaN   \n",
      "NB      NaN              NaN                          NaN   \n",
      "\n",
      "                             TabNet                          DT  \\\n",
      "LGB      (0.99078, 0.0011, 0.00812)   (0.99918, 0.00078, 4e-05)   \n",
      "XGB     (0.99132, 0.00172, 0.00696)         (0.999, 0.001, 0.0)   \n",
      "RF       (0.98662, 0.0021, 0.01128)     (0.99786, 0.00214, 0.0)   \n",
      "TabNet                          NaN  (0.5926, 0.13284, 0.27456)   \n",
      "DT                              NaN                         NaN   \n",
      "DNN                             NaN                         NaN   \n",
      "KNN                             NaN                         NaN   \n",
      "SVM                             NaN                         NaN   \n",
      "NB                              NaN                         NaN   \n",
      "\n",
      "                               DNN                       KNN  \\\n",
      "LGB        (0.99974, 0.00026, 0.0)           (1.0, 0.0, 0.0)   \n",
      "XGB        (0.99986, 0.00014, 0.0)           (1.0, 0.0, 0.0)   \n",
      "RF           (0.99994, 6e-05, 0.0)           (1.0, 0.0, 0.0)   \n",
      "TabNet  (0.91192, 0.0022, 0.08588)     (0.99996, 0.0, 4e-05)   \n",
      "DT      (0.69892, 0.29928, 0.0018)           (1.0, 0.0, 0.0)   \n",
      "DNN                            NaN  (0.9973, 8e-05, 0.00262)   \n",
      "KNN                            NaN                       NaN   \n",
      "SVM                            NaN                       NaN   \n",
      "NB                             NaN                       NaN   \n",
      "\n",
      "                                SVM                           NB  \n",
      "LGB                 (1.0, 0.0, 0.0)      (0.99978, 0.00022, 0.0)  \n",
      "XGB                 (1.0, 0.0, 0.0)      (0.99974, 0.00026, 0.0)  \n",
      "RF            (0.99998, 2e-05, 0.0)      (0.99888, 0.00112, 0.0)  \n",
      "TabNet      (0.99442, 0.0, 0.00558)     (0.9855, 6e-05, 0.01444)  \n",
      "DT      (0.99168, 0.00058, 0.00774)   (0.9644, 0.00164, 0.03396)  \n",
      "DNN      (0.95518, 0.0001, 0.04472)   (0.93888, 0.0002, 0.06092)  \n",
      "KNN     (0.28218, 0.00294, 0.71488)  (0.53166, 0.00068, 0.46766)  \n",
      "SVM                             NaN  (0.52572, 0.00362, 0.47066)  \n",
      "NB                              NaN                          NaN  \n",
      "decision_matrix=\n",
      "                 LGB           XGB            RF        TabNet            DT  \\\n",
      "LGB              NaN         equal  inconclusive       smaller       smaller   \n",
      "XGB            equal           NaN  inconclusive       smaller       smaller   \n",
      "RF      inconclusive  inconclusive           NaN  inconclusive       smaller   \n",
      "TabNet        larger        larger  inconclusive           NaN  inconclusive   \n",
      "DT            larger        larger        larger  inconclusive           NaN   \n",
      "DNN           larger        larger        larger  inconclusive  inconclusive   \n",
      "KNN           larger        larger        larger        larger        larger   \n",
      "SVM           larger        larger        larger        larger        larger   \n",
      "NB            larger        larger        larger  inconclusive  inconclusive   \n",
      "\n",
      "                 DNN           KNN           SVM            NB  \n",
      "LGB          smaller       smaller       smaller       smaller  \n",
      "XGB          smaller       smaller       smaller       smaller  \n",
      "RF           smaller       smaller       smaller       smaller  \n",
      "TabNet  inconclusive       smaller       smaller  inconclusive  \n",
      "DT      inconclusive       smaller       smaller  inconclusive  \n",
      "DNN              NaN       smaller  inconclusive  inconclusive  \n",
      "KNN           larger           NaN  inconclusive  inconclusive  \n",
      "SVM     inconclusive  inconclusive           NaN  inconclusive  \n",
      "NB      inconclusive  inconclusive  inconclusive           NaN  \n",
      "rope=0.1\n",
      "rope_mode=effsize\n",
      "effect_size=cohen_d)\n"
     ]
    }
   ],
   "source": [
    "result = autorank(df, alpha=0.01, verbose=True,approach = 'bayesian')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5bddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistical analysis was conducted for 9 populations with 11 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.010.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.138). Therefore, we assume that all populations are normal.\n",
      "We used a bayesian signed rank test to determine differences between the mean values of the populations and report the mean value (M) and the standard deviation (SD) for each population. We distinguish between populations being pair-wise smaller, equal, or larger and make a decision for one of these cases if we estimate that the posterior probability is at least alpha=0.010.\n",
      "We used the effect size to define the region of practical equivalence (ROPE) around the mean value dynamically as 0.100*d.\n",
      "We found significant and practically relevant differences between the populations LGB (M=0.851+-0.148, SD=0.081), XGB (M=0.851+-0.150, SD=0.082), RF (M=0.848+-0.154, SD=0.085), TabNet (M=0.817+-0.189, SD=0.103), DT (M=0.812+-0.181, SD=0.099), DNN (M=0.794+-0.208, SD=0.114), KNN (M=0.745+-0.178, SD=0.097), SVM (M=0.745+-0.121, SD=0.066), and NB (M=0.730+-0.145, SD=0.079).\n",
      "The mean value of the population LGB is larger than of the populations TabNet, DT, DNN, KNN, SVM, and NB.\n",
      "The mean value of the population XGB is larger than of the populations TabNet, DT, DNN, KNN, SVM, and NB.\n",
      "The mean value of the population RF is larger than of the populations DT, DNN, KNN, SVM, and NB.\n",
      "The mean value of the population TabNet is larger than of the populations KNN and SVM.\n",
      "The mean value of the population DT is larger than of the populations KNN and SVM.\n",
      "The mean value of the population DNN is larger than of the populations KNN.\n",
      "The following pairs of populations are equal: LGB and XGB.\n",
      "All other differences are inconclusive.\n"
     ]
    }
   ],
   "source": [
    "create_report(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e81c7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x162 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stats(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33072b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\begin{tabular}{lrrrlll}\n",
      "\\toprule\n",
      "{} &    MR &     M &    SD &              CI &    \\$d\\$ &   Magnitude \\\\\n",
      "\\midrule\n",
      "DT     & 8.364 & 0.635 & 0.060 &  [0.571, 0.698] &  0.000 &  negligible \\\\\n",
      "TabNet & 7.364 & 0.588 & 0.204 &  [0.372, 0.804] &  0.314 &       small \\\\\n",
      "DNN    & 5.727 & 0.708 & 0.090 &  [0.613, 0.803] & -0.959 &       large \\\\\n",
      "SVM    & 5.636 & 0.727 & 0.071 &  [0.652, 0.803] & -1.410 &       large \\\\\n",
      "KNN    & 5.364 & 0.723 & 0.064 &  [0.655, 0.791] & -1.422 &       large \\\\\n",
      "NB     & 5.273 & 0.729 & 0.057 &  [0.669, 0.789] & -1.622 &       large \\\\\n",
      "XGB    & 3.091 & 0.779 & 0.098 &  [0.675, 0.882] & -1.779 &       large \\\\\n",
      "LGB    & 2.273 & 0.785 & 0.096 &  [0.683, 0.887] & -1.879 &       large \\\\\n",
      "RF     & 1.909 & 0.795 & 0.086 &  [0.704, 0.887] & -2.163 &       large \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Summary of populations}\n",
      "\\label{tbl:stat_results}\n",
      "\\end{table}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\autorank\\autorank.py:697: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  table_string = table_df.to_latex(float_format=float_format, na_rep='-').strip()\n"
     ]
    }
   ],
   "source": [
    "latex_table(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c467f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
